{"instruction": "EXAMPLE 5.1 If we used a much smaller sample size of n = 50, would you guess that the standard error for ˆp", "response": "would be larger or smaller than when we used n = 1000? Intuitively, it seems like more data is better than less data, and generally that is correct! The typical error when p = 0.88 and n = 50 would be larger than the error we would expect when n = 1000."}
{"instruction": "EXAMPLE 5.2 Earlier we estimated the mean and standard error of ˆp using simulated data when p = 0.88 and", "response": "n = 1000. Confirm that the Central Limit Theorem applies and the sampling distribution is ap- proximately normal. Independence. There are n = 1000 observations for each sample proportion ˆp, and each of those observations are independent draws. The most common way for observations to be considered independent is if they are from a simple random sample. Success-failure condition. We can confirm the sample size is sufficiently large by checking the success-failure condition and confirming the two calculated values are greater than 10: np = 1000 × 0.88 = 880 ≥10 n(1 −p) = 1000 × (1 −0.88) = 120 ≥10 The independence and success-failure conditions are both satisfied, so the Central Limit Theorem applies, and it’s reasonable to model ˆp using a normal distribution."}
{"instruction": "EXAMPLE 5.3 Compute the theoretical mean and standard error of ˆp when p = 0.88 and n = 1000, according to", "response": "the Central Limit Theorem. The mean of the ˆp’s is simply the population proportion: µˆp = 0.88. The calculation of the standard error of ˆp uses the following formula: SEˆp = r p(1 −p) n = r"}
{"instruction": "EXAMPLE 5.4 Estimate how frequently the sample proportion ˆp should be within 0.02 (2%) of the population", "response": "value, p = 0.88. Based on"}
{"instruction": "EXAMPLE 5.7 In Figure 5.6, one interval does not contain p = 0.88. Does this imply that the population proportion", "response": "used in the simulation could not have been p = 0.88? Just as some observations naturally occur more than 1.96 standard deviations from the mean, some point estimates will be more than 1.96 standard errors from the parameter of interest. A confidence interval only provides a plausible range of values. While we might say other values are implausible based on the data, this does not mean they are impossible. 95% CONFIDENCE INTERVAL FOR A PARAMETER When the distribution of a point estimate qualifies for the Central Limit Theorem and therefore closely follows a normal distribution, we can construct a 95% confidence interval as point estimate ± 1.96 × SE"}
{"instruction": "EXAMPLE 5.8 In Section 5.1 we learned about a Pew Research poll where 88.7% of a random sample of 1000 Amer-", "response": "ican adults supported expanding the role of solar power. Compute and interpret a 95% confidence interval for the population proportion. We earlier confirmed that ˆp follows a normal distribution and has a standard error of SEˆp = 0.010. To compute the 95% confidence interval, plug the point estimate ˆp = 0.887 and standard error into the 95% confidence interval formula: ˆp ± 1.96 × SEˆp →"}
{"instruction": "EXAMPLE 5.11 What is the point estimate in this case, and is it reasonable to use a normal distribution to model", "response": "that point estimate? The point estimate, based on a sample of size n = 1042, is ˆp = 0.82. To check whether ˆp can be reasonably modeled using a normal distribution, we check independence (the poll is based on a simple random sample) and the success-failure condition (1042 × ˆp ≈854 and 1042 × (1 −ˆp) ≈188, both easily greater than 10). With the conditions met, we are assured that the sampling distribution of ˆp can be reasonably modeled using a normal distribution."}
{"instruction": "EXAMPLE 5.12 Estimate the standard error of ˆp = 0.82 from the Ebola survey.", "response": "We’ll use the substitution approximation of p ≈ˆp = 0.82 to compute the standard error: SEˆp = r p(1 −p) n ≈ r"}
{"instruction": "EXAMPLE 5.13 Construct a 95% confidence interval for p, the proportion of New York adults who supported a", "response": "quarantine for anyone who has come into contact with an Ebola patient. Using the standard error SE = 0.012 from"}
{"instruction": "EXAMPLE 5.18 It may seem impossible that the proportion of people who get the correct answer is exactly 33.3%.", "response": "If we don’t believe the null hypothesis, should we simply reject it? No. While we may not buy into the notion that the proportion is exactly 33.3%, the hypothesis testing framework requires that there be strong evidence before we reject the null hypothesis and conclude something more interesting. After all, even if we don’t believe the proportion is exactly 33.3%, that doesn’t really tell us anything useful! We would still be stuck with the original question: do people do better or worse than random guessing on Roslings’ question? Without data that strongly points in one direction or the other, it is both uninteresting and pointless to reject H0."}
{"instruction": "EXAMPLE 5.20 Check whether it is reasonable to construct a confidence interval for p using the sample data, and if", "response": "so, construct a 95% confidence interval. The conditions are met for ˆp to be approximately normal: the data come from a simple random sample (satisfies independence), and nˆp = 12 and n(1 −ˆp) = 38 are both at least 10 (success-failure condition). To construct the confidence interval, we will need to identify the point estimate (ˆp = 0.24), the critical value for the 95% confidence level (z⋆= 1.96), and the standard error of ˆp (SEˆp = p ˆp(1 −ˆp)/n ="}
{"instruction": "EXAMPLE 5.21 Explain why we cannot conclude that college-educated adults simply guessed on the infant vaccina-", "response": "tion question. While we failed to reject H0, that does not necessarily mean the null hypothesis is true. Perhaps there was an actual difference, but we were not able to detect it with the relatively small sample of 50. DOUBLE NEGATIVES CAN SOMETIMES BE USED IN STATISTICS In many statistical explanations, we use double negatives. For instance, we might say that the null hypothesis is not implausible or we failed to reject the null hypothesis. Double negatives are used to communicate that while we are not rejecting a position, we are also not saying it is correct. 16Arguably this method is slightly imprecise. As we’ll see in a few pages, the standard error is often computed slightly differently in the context of a hypothesis test for a proportion. 192 CHAPTER 5. FOUNDATIONS FOR INFERENCE"}
{"instruction": "EXAMPLE 5.24 Compute a 95% confidence interval for the fraction of college-educated adults who answered the", "response": "children-in-2100 question correctly, and evaluate the hypotheses in"}
{"instruction": "EXAMPLE 5.26 How could we reduce the Type 1 Error rate in US courts? What influence would this have on the", "response": "Type 2 Error rate? To lower the Type 1 Error rate, we might raise our standard for conviction from “beyond a reasonable doubt” to “beyond a conceivable doubt” so fewer people would be wrongly convicted. However, this would also make it more difficult to convict the people who are actually guilty, so we would make more Type 2 Errors."}
{"instruction": "EXAMPLE 5.28 Pew Research asked a random sample of 1000 American adults whether they supported the increased", "response": "usage of coal to produce energy. Set up hypotheses to evaluate whether a majority of American adults support or oppose the increased usage of coal. The uninteresting result is that there is no majority either way: half of Americans support and the other half oppose expanding the use of coal to produce energy. The alternative hypothesis would be that there is a majority support or oppose (though we do not known which one!) expanding the use of coal. If p represents the proportion supporting, then we can write the hypotheses as H0: p = 0.5 HA: p ̸= 0.5 In this case, the null value is p0 = 0.5. When evaluating hypotheses for proportions using the p-value method, we will slightly modify how we check the success-failure condition and compute the standard error for the single proportion case. These changes aren’t dramatic, but pay close attention to how we use the null value, p0."}
{"instruction": "EXAMPLE 5.29 Pew Research’s sample show that 37% of American adults support increased usage of coal. We now", "response": "wonder, does 37% represent a real difference from the null hypothesis of 50%? What would the sampling distribution of ˆp look like if the null hypothesis were true? If the null hypothesis were true, the population proportion would be the null value, 0.5. We previ- ously learned that the sampling distribution of ˆp will be normal when two conditions are met: Independence. The poll was based on a simple random sample, so independence is satisfied. Success-failure. Based on the poll’s sample size of n = 1000, the success-failure condition is met, since np H0 = 1000 × 0.5 = 500 n(1 −p) H0 = 1000 × (1 −0.5) = 500 are both at least 10. Note that the success-failure condition was checked using the null value, p0 = 0.5; this is the first procedural difference from confidence intervals. If the null hypothesis were true, the sampling distribution indicates that a sample proportion based on n = 1000 observations would be normally distributed. Next, we can compute the standard error, where we will again use the null value p0 = 0.5 in the calculation: SEˆp = r p(1 −p) n H0 = r"}
{"instruction": "EXAMPLE 5.31 How should we evaluate the hypotheses using the p-value of 4.4×10−16? Use the standard significance", "response": "level of α = 0.05. If the null hypothesis were true, there’s only an incredibly small chance of observing such an extreme deviation of ˆp from 0.5. This means one of the following must be true: 1. The null hypothesis is true, and we just happened to observe something so extreme that it only happens about once in every 23 quadrillion times (1 quadrillion = 1 million × 1 billion). 2. The alternative hypothesis is true, which would be consistent with observing a sample propor- tion far from 0.5. The first scenario is laughably improbable, while the second scenario seems much more plausible. Formally, when we evaluate a hypothesis test, we compare the p-value to the significance level, which in this case is α = 0.05. Since the p-value is less than α, we reject the null hypothesis. That is, the data provide strong evidence against H0. The data indicate the direction of the difference: a majority of Americans do not support expanding the use of coal-powered energy."}
{"instruction": "EXAMPLE 5.33 A simple random sample of 1028 US adults in March 2013 show that 56% support nuclear arms", "response": "reduction. Does this provide convincing evidence that a majority of Americans supported nuclear arms reduction at the 5% significance level? First, check conditions: Independence. The poll was of a simple random sample of US adults, meaning the observations are independent. Success-failure. In a one-proportion hypothesis test, this condition is checked using the null pro- portion, which is p0 = 0.5 in this context: np0 = n(1 −p0) = 1028 × 0.5 = 514 ≥10. With these conditions verified, we can model ˆp using a normal model. Next the standard error can be computed. The null value p0 is used again here, because this is a hypothesis test for a single proportion. SEˆp = r p0(1 −p0) n = r"}
{"instruction": "EXAMPLE 5.34 A car manufacturer is considering switching to a new, higher quality piece of equipment that con-", "response": "structs vehicle door hinges. They figure that they will save money in the long run if this new machine produces hinges that have flaws less than 0.2% of the time. However, if the hinges are flawed more than 0.2% of the time, they wouldn’t get a good enough return-on-investment from the new piece of equipment, and they would lose money. Is there good reason to modify the significance level in such a hypothesis test? The null hypothesis would be that the rate of flawed hinges is 0.2%, while the alternative is that it the rate is different than 0.2%. This decision is just one of many that have a marginal impact on the car and company. A significance level of 0.05 seems reasonable since neither a Type 1 or Type 2 Error should be dangerous or (relatively) much more expensive."}
{"instruction": "EXAMPLE 5.35 The same car manufacturer is considering a slightly more expensive supplier for parts related to", "response": "safety, not door hinges. If the durability of these safety components is shown to be better than the current supplier, they will switch manufacturers. Is there good reason to modify the significance level in such an evaluation? The null hypothesis would be that the suppliers’ parts are equally reliable. Because safety is involved, the car company should be eager to switch to the slightly more expensive manufacturer (reject H0), even if the evidence of increased safety is only moderately strong. A slightly larger significance level, such as α = 0.10, might be appropriate."}
{"instruction": "EXAMPLE 5.38 Why can’t we simply run a one-sided test that goes in the direction of the data?", "response": "We’ve been building a careful framework that controls for the Type 1 Error, which is the significance level α in a hypothesis test. We’ll use the α = 0.05 below to keep things simple. Imagine we could pick the one-sided test after we saw the data. What will go wrong? • If ˆp is smaller than the null value, then a one-sided test where p < p0 would mean that any observation in the lower 5% tail of the null distribution would lead to us rejecting H0. • If ˆp is larger than the null value, then a one-sided test where p > p0 would mean that any observation in the upper 5% tail of the null distribution would lead to us rejecting H0. Then if H0 were true, there’s a 10% chance of being in one of the two tails, so our testing error is actually α = 0.10, not 0.05. That is, not being careful about when to use one-sided tests effectively undermines the methods we’re working so hard to develop and utilize. 202 CHAPTER 5. FOUNDATIONS FOR INFERENCE"}
{"instruction": "EXAMPLE 7.1 Consider the following two plots that come from simple random samples from different populations.", "response": "Their sample sizes are n1 = 15 and n2 = 50. Sample 1 Observations (n = 15) 0 2 4 6 0 1 2 3 4 Frequency Sample 2 Observations (n = 50) 0 10 20 0 5 10 15 20 25 Frequency Are the independence and normality conditions met in each case? Each samples is from a simple random sample of its respective population, so the independence condition is satisfied. Let’s next check the normality condition for each using the rule of thumb. The first sample has fewer than 30 observations, so we are watching for any clear outliers. None are present; while there is a small gap in the histogram between 5 and 6, this gap is small and 20% of the observations in this small sample are represented in that far right bar of the histogram, so we can hardly call these clear outliers. With no clear outliers, the normality condition is reasonably met. The second sample has a sample size greater than 30 and includes an outlier that appears to be roughly 5 times further from the center of the distribution than the next furthest observation. This is an"}
{"instruction": "EXAMPLE 7.2 What proportion of the t-distribution with 18 degrees of freedom falls below -2.10?", "response": "Just like a normal probability problem, we first draw the picture in Figure 7.3 and shade the area below -2.10. Using statistical software, we can obtain a precise value: 0.0250."}
{"instruction": "EXAMPLE 7.3 A t-distribution with 20 degrees of freedom is shown in the left panel of Figure 7.4. Estimate the", "response": "proportion of the distribution falling above 1.65. With a normal distribution, this would correspond to about 0.05, so we should expect the t- distribution to give us a value in this neighborhood. Using statistical software: 0.0573."}
{"instruction": "EXAMPLE 7.4 A t-distribution with 2 degrees of freedom is shown in the right panel of Figure 7.4. Estimate the", "response": "proportion of the distribution falling more than 3 units from the mean (above or below). With so few degrees of freedom, the t-distribution will give a more notably different value than the normal distribution. Under a normal distribution, the area would be about 0.003 using the 68-95-"}
{"instruction": "EXAMPLE 7.6 Are the independence and normality conditions satisfied for this data set?", "response": "The observations are a simple random sample, therefore independence is reasonable. The summary statistics in Figure 7.6 do not suggest any clear outliers, since all observations are within 2.5 standard deviations of the mean. Based on this evidence, the normality condition seems reasonable. In the normal model, we used z⋆and the standard error to determine the width of a confidence interval. We revise the confidence interval formula slightly when using the t-distribution: point estimate ± t⋆ df × SE → ¯x ± t⋆ df × s √n"}
{"instruction": "EXAMPLE 7.7 Using the summary statistics in Figure 7.6, compute the standard error for the average mercury", "response": "content in the n = 19 dolphins. We plug in s and n into the formula: SE = s/√n = 2.3/ √ 19 = 0.528. 256 CHAPTER 7. INFERENCE FOR NUMERICAL DATA The value t⋆ df is a cutoff we obtain based on the confidence level and the t-distribution with df degrees of freedom. That cutoff is found in the same way as with a normal distribution: we find t⋆ df such that the fraction of the t-distribution with df degrees of freedom within a distance t⋆ df of 0 matches the confidence level of interest."}
{"instruction": "EXAMPLE 7.8 When n = 19, what is the appropriate degrees of freedom? Find t⋆", "response": "df for this degrees of freedom and the confidence level of 95% The degrees of freedom is easy to calculate: df = n −1 = 18. Using statistical software, we find the cutoff where the upper tail is equal to 2.5%: t⋆ 18 = 2.10. The area below -2.10 will also be equal to 2.5%. That is, 95% of the t-distribution with df = 18 lies within 2.10 units of 0."}
{"instruction": "EXAMPLE 7.9 Compute and interpret the 95% confidence interval for the average mercury content in Risso’s", "response": "dolphins. We can construct the confidence interval as ¯x ± t⋆ 18 × SE →"}
{"instruction": "EXAMPLE 7.16 With both the independence and normality conditions satisfied, we can proceed with a hypothesis", "response": "test using the t-distribution. The sample mean and sample standard deviation of the sample of 100 runners from the 2017 Cherry Blossom Race are 97.32 and 16.98 minutes, respectively. Recall that the sample size is 100 and the average run time in 2006 was 93.29 minutes. Find the test statistic and p-value. What is your conclusion? To find the test statistic (T-score), we first must determine the standard error: SE = 16.98/ √ 100 = 1.70 Now we can compute the T-score using the sample mean (97.32), null value (93.29), and SE: T = 97.32 −93.29"}
{"instruction": "EXAMPLE 7.17 Set up a hypothesis test to determine whether, on average, there is a difference between Amazon’s", "response": "price for a book and the UCLA bookstore’s price. Also, check the conditions for whether we can move forward with the test using the t-distribution. We are considering two scenarios: there is no difference or there is some difference in average prices. H0: µdiff = 0. There is no difference in the average textbook price. HA: µdiff ̸= 0. There is a difference in average prices. Next, we check the independence and normality conditions. The observations are based on a simple random sample, so independence is reasonable. While there are some outliers, n = 68 and none of the outliers are particularly extreme, so the normality of ¯x is satisfied. With these conditions satisfied, we can move forward with the t-distribution."}
{"instruction": "EXAMPLE 7.21 Can the t-distribution be used to make inference using the point estimate, ¯xesc −¯xcontrol = 7.83?", "response": "First, we check for independence. Because the sheep were randomized into the groups, independence within and between groups is satisfied. Figure 7.12 does not reveal any clear outliers in either group. (The ESC group does look a bit more variability, but this is not the same as having clear outliers.) With both conditions met, we can use the t-distribution to model the difference of sample means. −10% −5% 0% 5% 10% 15% Embryonic stem cell transplant Change in heart pumping function 0 1 2 3 −10% −5% 0% 5% 10% 15% 0 1 2 3 Control (no treatment) Change in heart pumping function Figure 7.12: Histograms for both the embryonic stem cell and control group. As with the one-sample case, we always compute the standard error using sample standard deviations rather than population standard deviations: SE = s s2esc nesc + s2 control ncontrol = r"}
{"instruction": "EXAMPLE 7.22 Calculate a 95% confidence interval for the effect of ESCs on the change in heart pumping capacity", "response": "of sheep after they’ve suffered a heart attack. We will use the sample difference and the standard error that we computed earlier calculations: ¯xesc −¯xcontrol = 7.83 SE = r"}
{"instruction": "EXAMPLE 7.23 Set up appropriate hypotheses to evaluate whether there is a relationship between a mother smoking", "response": "and average birth weight. The null hypothesis represents the case of no difference between the groups. H0: There is no difference in average birth weight for newborns from mothers who did and did not smoke. In statistical notation: µn −µs = 0, where µn represents non-smoking mothers and µs represents mothers who smoked. HA: There is some difference in average newborn weights from mothers who did and did not smoke (µn −µs ̸= 0). We check the two conditions necessary to model the difference in sample means using the t-distribution. • Because the data come from a simple random sample, the observations are independent, both within and between samples. • With both data sets over 30 observations, we inspect the data in Figure 7.14 for any particularly extreme outliers and find none. Since both conditions are satisfied, the difference in sample means may be modeled using a t- distribution. Mothers Who Smoked Newborn Weights (lbs) 0 2 4 6 8 10 Mothers Who Did Not Smoke Newborn Weights (lbs) 0 2 4 6 8 10 Figure 7.14: The left panel represents birth weights for infants whose mothers smoked. The right panel represents the birth weights for infants whose mothers who did not smoke."}
{"instruction": "EXAMPLE 7.30 Identify the p-value depicted in Figure 7.17 using df = 26, and provide a conclusion in the context", "response": "of the case study. Using software, we can find the one-tail area (0.13) and then double this value to get the two-tail area, which is the p-value: 0.26. (Alternatively, we could use the t-table in Appendix C.2.) In"}
{"instruction": "EXAMPLE 7.31 Suppose a pharmaceutical company has developed a new drug for lowering blood pressure, and they", "response": "are preparing a clinical trial (experiment) to test the drug’s effectiveness. They recruit people who are taking a particular standard blood pressure medication. People in the control group will continue to take their current medication through generic-looking pills to ensure blinding. Write down the hypotheses for a two-sided hypothesis test in this context. Generally, clinical trials use a two-sided alternative hypothesis, so below are suitable hypotheses for this context: H0: The new drug performs exactly as well as the standard medication. µtrmt −µctrl = 0. HA: The new drug’s performance differs from the standard medication. µtrmt −µctrl ̸= 0."}
{"instruction": "EXAMPLE 7.32 The researchers would like to run the clinical trial on patients with systolic blood pressures between", "response": "140 and 180 mmHg. Suppose previously published studies suggest that the standard deviation of the patients’ blood pressures will be about 12 mmHg and the distribution of patient blood pressures will be approximately symmetric.26 If we had 100 patients per group, what would be the approximate standard error for ¯xtrmt −¯xctrl? The standard error is calculated as follows: SE¯xtrmt−¯xctrl = s s2 trmt ntrmt + s2 ctrl nctrl = r 122 100 + 122 100 = 1.70 This may be an imperfect estimate of SE¯xtrmt−¯xctrl, since the standard deviation estimate we used may not be perfectly correct for this group of patients. However, it is sufficient for our purposes. 25Even though we don’t cover it explicitly, similar sample size planning is also helpful for observational studies. 26In this particular study, we’d generally measure each patient’s blood pressure at the beginning and end of the study, and then the outcome measurement for the study would be the average change in blood pressure. That is, both µtrmt and µctrl would represent average differences. This is what you might think of as a 2-sample paired testing structure, and we’d analyze it exactly just like a hypothesis test for a difference in the average change for patients. In the calculations we perform here, we’ll suppose that 12 mmHg is the predicted standard deviation of a patient’s blood pressure difference over the course of the study."}
{"instruction": "EXAMPLE 7.33 What does the null distribution of ¯xtrmt −¯xctrl look like?", "response": "The degrees of freedom are greater than 30, so the distribution of ¯xtrmt −¯xctrl will be approximately normal. The standard deviation of this distribution (the standard error) would be about 1.70, and under the null hypothesis, its mean would be 0. −9 −6 −3 0 3 6 9 xtrmt −xctrl Null distribution"}
{"instruction": "EXAMPLE 7.34 For what values of ¯xtrmt −¯xctrl would we reject the null hypothesis?", "response": "For α = 0.05, we would reject H0 if the difference is in the lower 2.5% or upper 2.5% tail: Lower 2.5%: For the normal model, this is 1.96 standard errors below 0, so any difference smaller than −1.96 × 1.70 = −3.332 mmHg. Upper 2.5%: For the normal model, this is 1.96 standard errors above 0, so any difference larger than 1.96 × 1.70 = 3.332 mmHg. The boundaries of these rejection regions are shown below: −9 −6 −3 0 3 6 9 xtrmt −xctrl Null distribution Reject H0 Do not reject H0 Reject H0 Next, we’ll perform some hypothetical calculations to determine the probability we reject the null hypothesis, if the alternative hypothesis were actually true."}
{"instruction": "EXAMPLE 7.35 Suppose we decided to move forward with 100 patients per treatment group and the new drug", "response": "reduces blood pressure by an additional 3 mmHg relative to the standard medication. What is the probability that we detect a drop? Before we even do any calculations, notice that if ¯xtrmt −¯xctrl = −3 mmHg, there wouldn’t even be sufficient evidence to reject H0. That’s not a good sign. To calculate the probability that we will reject H0, we need to determine a few things: • The sampling distribution for ¯xtrmt −¯xctrl when the true difference is -3 mmHg. This is the same as the null distribution, except it is shifted to the left by 3: −9 −6 −3 0 3 6 9 xtrmt −xctrl Null distribution Distribution with µtrmt −µctrl = −3 • The rejection regions, which are outside of the dotted lines above. • The fraction of the distribution that falls in the rejection region. In short, we need to calculate the probability that x < −3.332 for a normal distribution with mean -3 and standard deviation 1.7. To do so, we first shade the area we want to calculate: −9 −6 −3 0 3 6 9 xtrmt −xctrl Null distribution Distribution with µtrmt −µctrl = −3 We’ll use a normal approximation, which is good approximation when the degrees of freedom is about 30 or more. We’ll start by calculating the Z-score and find the tail area using either statistical software or the probability table: Z = −3.332 −(−3)"}
{"instruction": "EXAMPLE 7.37 What sample size will lead to a power of 80%? Use α = 0.05.", "response": "We’ll assume we have a large enough sample that the normal distribution is a good approximation for the test statistic, since the normal distribution and the t-distribution look almost identical when the degrees of freedom are moderately large (e.g. df ≥30). If that doesn’t turn out to be true, then we’d need to make a correction. We start by identifying the Z-score that would give us a lower tail of 80%. For a moderately large sample size per group, the Z-score for a lower tail of 80% would be about Z = 0.84. −9 −6 −3 0 3 6 9 xtrmt −xctrl Null distribution Distribution with µtrmt −µctrl = −3"}
{"instruction": "EXAMPLE 7.40 College departments commonly run multiple lectures of the same introductory course each semester", "response": "because of high demand. Consider a statistics department that runs three lectures of an introductory statistics course. We might like to determine whether there are statistically significant differences in first exam scores in these three classes (A, B, and C). Describe appropriate hypotheses to determine whether there are any differences between the three classes. The hypotheses may be written in the following form: H0: The average score is identical in all lectures. Any observed difference is due to chance. Nota- tionally, we write µA = µB = µC. HA: The average score varies by class. We would reject the null hypothesis in favor of the alternative hypothesis if there were larger differences among the class averages than what we might expect from chance alone. Strong evidence favoring the alternative hypothesis in ANOVA is described by unusually large differences among the group means. We will soon learn that assessing the variability of the group means relative to the variability among individual observations within each group is key to ANOVA’s success. 286 CHAPTER 7. INFERENCE FOR NUMERICAL DATA"}
{"instruction": "EXAMPLE 7.41 Examine Figure 7.19. Compare groups I, II, and III. Can you visually determine if the differences in", "response": "the group centers is due to chance or not? Now compare groups IV, V, and VI. Do these differences appear to be due to chance? Any real difference in the means of groups I, II, and III is difficult to discern, because the data within each group are very volatile relative to any differences in the average outcome. On the other hand, it appears there are differences in the centers of groups IV, V, and VI. For instance, group V appears to have a higher mean than that of the other two groups. Investigating groups IV, V, and VI, we see the differences in the groups’ centers are noticeable because those differences are large relative to the variability in the individual observations within each group. Outcome −1 0 1 2 3 4 I II III IV V VI Figure 7.19: Side-by-side dot plot for the outcomes for six groups."}
{"instruction": "EXAMPLE 7.43 The player positions have been divided into three groups: outfield (OF), infield (IF), and catcher (C).", "response": "What would be an appropriate point estimate of the on-base percentage by outfielders, µOF? A good estimate of the on-base percentage by outfielders would be the sample average of OBP for just those players whose position is outfield: ¯xOF = 0.320. Figure 7.22 provides summary statistics for each group. A side-by-side box plot for the on- base percentage is shown in Figure 7.23. Notice that the variability appears to be approximately constant across groups; nearly constant variance across groups is an important assumption that must be satisfied before we consider the ANOVA approach. OF IF C Sample size (ni) 160 205 64 Sample mean (¯xi)"}
{"instruction": "EXAMPLE 7.44 The largest difference between the sample means is between the catcher and the outfielder positions.", "response": "Consider again the original hypotheses: H0: µOF = µIF = µC HA: The average on-base percentage (µi) varies across some (or all) groups. Why might it be inappropriate to run the test by simply estimating whether the difference of µC and µOF is statistically significant at a 0.05 significance level? The primary issue here is that we are inspecting the data before picking the groups that will be compared. It is inappropriate to examine all data by eye (informal testing) and only afterwards decide which parts to formally test. This is called data snooping or data fishing. Naturally, we would pick the groups with the large differences for the formal test, and this would leading to an inflation in the Type 1 Error rate. To understand this better, let’s consider a slightly different problem. Suppose we are to measure the aptitude for students in 20 classes in a large elementary school at the beginning of the year. In this school, all students are randomly assigned to classrooms, so any differences we observe between the classes at the start of the year are completely due to chance. However, with so many groups, we will probably observe a few groups that look rather different from each other. If we select only these classes that look so different and then perform a formal test, we will probably make the wrong conclusion that the assignment wasn’t random. While we might only formally test differences for a few pairs of classes, we informally evaluated the other classes by eye before choosing the most extreme cases for a comparison. For additional information on the ideas expressed in"}
{"instruction": "EXAMPLE 7.46 The p-value corresponding to the shaded area in Figure 7.24 is equal to about 0.0066. Does this", "response": "provide strong evidence against the null hypothesis? The p-value is smaller than 0.05, indicating the evidence is strong enough to reject the null hypothesis at a significance level of 0.05. That is, the data provide strong evidence that the average on-base percentage varies by player’s primary field position."}
